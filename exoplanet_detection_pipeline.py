"""
Exoplanet Detection Pipeline
============================

Bu modÃ¼l, geliÅŸtirdiÄŸimiz tÃ¼m sistemleri entegre eden kapsamlÄ± bir 
exoplanet detection pipeline'Ä± saÄŸlar.

Ã–zellikler:
- CSV dosyalarÄ±nÄ± okuma ve iÅŸleme
- Ã–zellik Ã§Ä±karÄ±mÄ± (feature extraction)
- GeliÅŸtirilmiÅŸ Fuzzy Logic analizi
- Ã–zelleÅŸtirilmiÅŸ PPO ajanlarÄ± ile eÄŸitim
- SonuÃ§larÄ± CSV formatÄ±nda kaydetme
- GÃ¶rselleÅŸtirme ve raporlama

KullanÄ±m:
    pipeline = ExoplanetDetectionPipeline()
    results = pipeline.process_csv('data.csv')
    pipeline.save_results(results, 'output.csv')
"""

import pandas as pd
import numpy as np
import os
import json
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# Kendi modÃ¼llerimizi import et
from fuzzy_logic_system import ExoplanetFuzzySystem
from enhanced_fuzzy_rules import EnhancedFuzzyRuleGenerator
from enhanced_ppo_agents import EnhancedMultiAgentPPOTrainer, FuzzyOutputType, AgentType
from integrated_system import IntegratedExoplanetSystem
from preprocess import preprocess_data
from audio_inspired_preprocessor import AudioInspiredPreprocessor


class ExoplanetDetectionPipeline:
    """
    KapsamlÄ± Exoplanet Detection Pipeline
    
    Bu sÄ±nÄ±f, tÃ¼m geliÅŸtirdiÄŸimiz sistemleri entegre ederek
    CSV dosyalarÄ±ndan exoplanet tespiti yapan bir pipeline saÄŸlar.
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        Pipeline'Ä± baÅŸlat
        
        Args:
            config: Pipeline konfigÃ¼rasyonu
        """
        self.config = config or self._get_default_config()
        self.results_history = []
        self.processing_stats = {}
        
        # Sistemleri baÅŸlat
        self._initialize_systems()
        
        print("ğŸš€ Exoplanet Detection Pipeline BaÅŸlatÄ±ldÄ±!")
        print("=" * 60)
        self._print_system_info()
    
    def _get_default_config(self) -> Dict:
        """VarsayÄ±lan konfigÃ¼rasyon"""
        return {
            'fuzzy_system': {
                'enable_enhanced_rules': True,
                'rule_count_target': 200
            },
            'ppo_system': {
                'enable_specialized_agents': True,
                'episodes_per_combination': 50,
                'enable_training': True
            },
            'preprocessing': {
                'enable_audio_features': True,
                'normalize_features': True,
                'handle_missing_values': True
            },
            'output': {
                'save_intermediate_results': True,
                'create_visualizations': True,
                'detailed_reports': True
            }
        }
    
    def _initialize_systems(self):
        """TÃ¼m sistemleri baÅŸlat"""
        print("ğŸ”§ Sistemler baÅŸlatÄ±lÄ±yor...")
        
        # Fuzzy Logic Sistemi
        self.fuzzy_system = ExoplanetFuzzySystem()
        print("âœ“ Fuzzy Logic Sistemi hazÄ±r")
        
        # Enhanced Fuzzy Rules
        if self.config.get('fuzzy_system', {}).get('enable_enhanced_rules', True):
            self.enhanced_rules = EnhancedFuzzyRuleGenerator()
            print("âœ“ GeliÅŸtirilmiÅŸ Fuzzy KurallarÄ± hazÄ±r")
        
        # PPO Sistemi - Gerekli parametreler olmadan baÅŸlatmayacaÄŸÄ±z
        self.ppo_trainer = None
        if self.config.get('ppo_system', {}).get('enable_specialized_agents', True):
            print("âœ“ PPO sistemi hazÄ±r (gerektiÄŸinde baÅŸlatÄ±lacak)")
        
        # Audio Preprocessor
        if self.config.get('preprocessing', {}).get('enable_audio_features', True):
            self.audio_processor = AudioInspiredPreprocessor()
            print("âœ“ Audio-Inspired Preprocessor hazÄ±r")
        
        # Entegre Sistem
        self.integrated_system = None  # GerektiÄŸinde baÅŸlatÄ±lacak
        
        print("âœ… TÃ¼m sistemler baÅŸarÄ±yla baÅŸlatÄ±ldÄ±!\n")
    
    def _print_system_info(self):
        """Sistem bilgilerini yazdÄ±r"""
        print("ğŸ“Š SÄ°STEM BÄ°LGÄ°LERÄ°:")
        print(f"  â€¢ Fuzzy Logic: {'âœ“ Aktif' if self.fuzzy_system else 'âœ— Pasif'}")
        print(f"  â€¢ Enhanced Rules: {'âœ“ Aktif' if hasattr(self, 'enhanced_rules') else 'âœ— Pasif'}")
        print(f"  â€¢ PPO Agents: {'âœ“ Aktif' if hasattr(self, 'ppo_trainer') else 'âœ— Pasif'}")
        print(f"  â€¢ Audio Features: {'âœ“ Aktif' if hasattr(self, 'audio_processor') else 'âœ— Pasif'}")
        print()
    
    def process_csv(self, csv_path: str, output_dir: str = None) -> Dict[str, Any]:
        """
        CSV dosyasÄ±nÄ± iÅŸle ve exoplanet tespiti yap
        
        Args:
            csv_path: Ä°ÅŸlenecek CSV dosyasÄ±nÄ±n yolu
            output_dir: Ã‡Ä±ktÄ± dizini (varsayÄ±lan: 'pipeline_results')
            
        Returns:
            Ä°ÅŸlem sonuÃ§larÄ± dictionary'si
        """
        print(f"ğŸ“ CSV Ä°ÅŸleme BaÅŸlatÄ±ldÄ±: {csv_path}")
        print("=" * 60)
        
        # Ã‡Ä±ktÄ± dizinini hazÄ±rla
        if output_dir is None:
            output_dir = f"pipeline_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        os.makedirs(output_dir, exist_ok=True)
        
        try:
            # 1. CSV'yi oku
            print("ğŸ“– 1. CSV DosyasÄ± Okunuyor...")
            data = self._load_csv(csv_path)
            
            # 2. Veri Ã¶n iÅŸleme
            print("ğŸ”§ 2. Veri Ã–n Ä°ÅŸleme...")
            processed_data = self._preprocess_data(data)
            
            # 3. Ã–zellik Ã§Ä±karÄ±mÄ±
            print("ğŸ¯ 3. Ã–zellik Ã‡Ä±karÄ±mÄ±...")
            features = self._extract_features(processed_data)
            
            # 4. Fuzzy Logic analizi
            print("ğŸ§  4. Fuzzy Logic Analizi...")
            fuzzy_results = self._run_fuzzy_analysis(features)
            
            # 5. PPO analizi (eÄŸer etkinse)
            ppo_results = None
            if self.config['ppo_system']['enable_training']:
                print("ğŸ¤– 5. PPO AjanlarÄ± EÄŸitimi...")
                ppo_results = self._run_ppo_analysis(features)
            
            # 6. SonuÃ§larÄ± birleÅŸtir
            print("ğŸ“Š 6. SonuÃ§lar BirleÅŸtiriliyor...")
            combined_results = self._combine_results(
                data, features, fuzzy_results, ppo_results
            )
            
            # 7. SonuÃ§larÄ± kaydet
            print("ğŸ’¾ 7. SonuÃ§lar Kaydediliyor...")
            self._save_results(combined_results, output_dir)
            
            # 8. GÃ¶rselleÅŸtirme
            if self.config.get('output', {}).get('create_visualizations', True):
                print("ğŸ“ˆ 8. GÃ¶rselleÅŸtirmeler OluÅŸturuluyor...")
                self._create_visualizations(combined_results, output_dir)
            
            # 9. Rapor oluÅŸtur
            if self.config.get('output', {}).get('detailed_reports', True):
                print("ğŸ“‹ 9. DetaylÄ± Rapor OluÅŸturuluyor...")
                self._create_report(combined_results, output_dir)
            
            print("\nğŸ‰ Pipeline Ä°ÅŸlemi BaÅŸarÄ±yla TamamlandÄ±!")
            print(f"ğŸ“ SonuÃ§lar: {output_dir}")
            
            return {
                'status': 'success',
                'output_dir': output_dir,
                'results': combined_results,
                'processing_stats': self.processing_stats
            }
            
        except Exception as e:
            print(f"âŒ Pipeline HatasÄ±: {e}")
            import traceback
            traceback.print_exc()
            return {
                'status': 'error',
                'error': str(e),
                'output_dir': output_dir
            }
    
    def _load_csv(self, csv_path: str) -> pd.DataFrame:
        """CSV dosyasÄ±nÄ± yÃ¼kle"""
        if not os.path.exists(csv_path):
            raise FileNotFoundError(f"CSV dosyasÄ± bulunamadÄ±: {csv_path}")
        
        data = pd.read_csv(csv_path)
        print(f"  âœ“ {len(data)} satÄ±r, {len(data.columns)} sÃ¼tun yÃ¼klendi")
        
        # Temel istatistikler
        self.processing_stats['input_data'] = {
            'rows': len(data),
            'columns': len(data.columns),
            'missing_values': data.isnull().sum().sum(),
            'memory_usage': data.memory_usage(deep=True).sum()
        }
        
        return data
    
    def _preprocess_data(self, data: pd.DataFrame) -> pd.DataFrame:
        """Veriyi Ã¶n iÅŸle"""
        processed_data = data.copy()
        
        # Eksik deÄŸerleri iÅŸle
        if self.config.get('preprocessing', {}).get('handle_missing_values', True):
            # SayÄ±sal sÃ¼tunlar iÃ§in ortalama ile doldur
            numeric_columns = processed_data.select_dtypes(include=[np.number]).columns
            processed_data[numeric_columns] = processed_data[numeric_columns].fillna(
                processed_data[numeric_columns].mean()
            )
            print(f"  âœ“ {len(numeric_columns)} sayÄ±sal sÃ¼tunda eksik deÄŸerler dolduruldu")
        
        # Normalizasyon
        if self.config.get('preprocessing', {}).get('normalize_features', True):
            numeric_columns = processed_data.select_dtypes(include=[np.number]).columns
            # Label sÃ¼tununu normalizasyondan hariÃ§ tut
            feature_columns = [col for col in numeric_columns if col.lower() not in ['label', 'target', 'class']]
            
            if feature_columns:
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                processed_data[feature_columns] = scaler.fit_transform(processed_data[feature_columns])
                print(f"  âœ“ {len(feature_columns)} Ã¶zellik normalize edildi")
        
        self.processing_stats['preprocessing'] = {
            'normalized_features': len(feature_columns) if 'feature_columns' in locals() else 0,
            'final_shape': processed_data.shape
        }
        
        return processed_data
    
    def _extract_features(self, data: pd.DataFrame) -> Dict[str, Any]:
        """Ã–zellik Ã§Ä±karÄ±mÄ± yap"""
        features = {}
        
        # Temel Ã¶zellikler
        numeric_columns = data.select_dtypes(include=[np.number]).columns
        feature_columns = [col for col in numeric_columns if col.lower() not in ['label', 'target', 'class']]
        
        features['basic_features'] = data[feature_columns].values
        features['feature_names'] = list(feature_columns)
        
        # Audio-inspired Ã¶zellikler (eÄŸer etkinse)
        if hasattr(self, 'audio_processor'):
            try:
                # Ä°lk birkaÃ§ Ã¶zelliÄŸi kullanarak audio features Ã§Ä±kar
                sample_data = data[feature_columns].iloc[:min(100, len(data))]
                audio_features = []
                
                for idx, row in sample_data.iterrows():
                    try:
                        audio_feat = self.audio_processor.extract_audio_features(row.values)
                        audio_features.append(audio_feat)
                    except:
                        # Hata durumunda sÄ±fÄ±r vektÃ¶r ekle
                        audio_features.append(np.zeros(10))
                
                features['audio_features'] = np.array(audio_features)
                print(f"  âœ“ {len(audio_features)} Ã¶rnek iÃ§in audio Ã¶zellikler Ã§Ä±karÄ±ldÄ±")
                
            except Exception as e:
                print(f"  âš ï¸ Audio Ã¶zellik Ã§Ä±karÄ±mÄ±nda hata: {e}")
                features['audio_features'] = None
        
        # Label bilgisi (varsa)
        label_columns = [col for col in data.columns if col.lower() in ['label', 'target', 'class']]
        if label_columns:
            features['labels'] = data[label_columns[0]].values
            print(f"  âœ“ Label sÃ¼tunu bulundu: {label_columns[0]}")
        else:
            features['labels'] = None
            print("  â„¹ï¸ Label sÃ¼tunu bulunamadÄ±")
        
        self.processing_stats['feature_extraction'] = {
            'basic_feature_count': len(feature_columns),
            'audio_feature_count': features['audio_features'].shape[1] if features['audio_features'] is not None else 0,
            'sample_count': len(features['basic_features'])
        }
        
        return features
    
    def _run_fuzzy_analysis(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """Fuzzy Logic analizi Ã§alÄ±ÅŸtÄ±r"""
        try:
            # Temel Ã¶zellikleri DataFrame'e Ã§evir
            feature_df = pd.DataFrame(
                features['basic_features'], 
                columns=features['feature_names']
            )
            
            # Fuzzy predictions
            predictions = self.fuzzy_system.predict(feature_df)
            probabilities = predictions / 100.0  # 0-1 aralÄ±ÄŸÄ±na normalize et
            
            # Enhanced rules (eÄŸer etkinse)
            enhanced_rules = None
            if hasattr(self, 'enhanced_rules'):
                try:
                    enhanced_rules = self.enhanced_rules.generate_comprehensive_rules()
                    print(f"  âœ“ {len(enhanced_rules)} geliÅŸtirilmiÅŸ kural oluÅŸturuldu")
                except Exception as e:
                    print(f"  âš ï¸ Enhanced rules hatasÄ±: {e}")
            
            # SonuÃ§larÄ± hesapla
            binary_predictions = (probabilities > 0.5).astype(int)
            
            # Accuracy hesapla (eÄŸer label varsa)
            accuracy = None
            if features['labels'] is not None:
                accuracy = np.mean(binary_predictions == features['labels'])
                print(f"  âœ“ Fuzzy Logic Accuracy: {accuracy:.4f}")
            
            return {
                'predictions': predictions,
                'probabilities': probabilities,
                'binary_predictions': binary_predictions,
                'accuracy': accuracy,
                'enhanced_rules': enhanced_rules,
                'rule_count': len(enhanced_rules) if enhanced_rules else 0
            }
            
        except Exception as e:
            print(f"  âŒ Fuzzy analiz hatasÄ±: {e}")
            return {'error': str(e)}
    
    def _run_ppo_analysis(self, features: Dict[str, Any]) -> Dict[str, Any]:
        """PPO analizi Ã§alÄ±ÅŸtÄ±r"""
        try:
            # Entegre sistemi baÅŸlat (eÄŸer henÃ¼z baÅŸlatÄ±lmamÄ±ÅŸsa)
            if self.integrated_system is None:
                # GeÃ§ici bir CSV dosyasÄ± oluÅŸtur
                temp_csv = 'temp_pipeline_data.csv'
                temp_df = pd.DataFrame(features['basic_features'], columns=features['feature_names'])
                if features['labels'] is not None:
                    temp_df['label'] = features['labels']
                temp_df.to_csv(temp_csv, index=False)
                
                self.integrated_system = IntegratedExoplanetSystem(
                    data_path=temp_csv,
                    use_enhanced_system=True
                )
            
            # PPO eÄŸitimi Ã§alÄ±ÅŸtÄ±r
            episodes = self.config['ppo_system']['episodes_per_combination']
            training_results = self.ppo_trainer.train_specialized_agents(
                episodes_per_combination=episodes
            )
            
            print(f"  âœ“ {len(training_results)} PPO ajanÄ± eÄŸitildi")
            
            # En iyi performans gÃ¶steren ajanlarÄ± bul
            best_agents = {}
            for agent_key, results in training_results.items():
                reward = results.get('final_avg_reward', 0)
                fuzzy_type = agent_key.split('_')[0] + '_' + agent_key.split('_')[1]  # fuzzy output type
                
                if fuzzy_type not in best_agents or reward > best_agents[fuzzy_type]['reward']:
                    best_agents[fuzzy_type] = {
                        'agent_key': agent_key,
                        'reward': reward,
                        'results': results
                    }
            
            return {
                'training_results': training_results,
                'best_agents': best_agents,
                'total_agents': len(training_results),
                'avg_reward': np.mean([r.get('final_avg_reward', 0) for r in training_results.values()])
            }
            
        except Exception as e:
            print(f"  âŒ PPO analiz hatasÄ±: {e}")
            return {'error': str(e)}
    
    def _combine_results(self, original_data: pd.DataFrame, features: Dict[str, Any], 
                        fuzzy_results: Dict[str, Any], ppo_results: Dict[str, Any]) -> Dict[str, Any]:
        """TÃ¼m sonuÃ§larÄ± birleÅŸtir"""
        
        combined = {
            'input_data': {
                'shape': original_data.shape,
                'columns': original_data.columns.tolist(),
                'sample_data': original_data.head().to_dict()
            },
            'features': {
                'basic_feature_count': len(features['feature_names']),
                'feature_names': features['feature_names'],
                'has_labels': features['labels'] is not None,
                'sample_count': len(features['basic_features'])
            },
            'fuzzy_analysis': fuzzy_results,
            'ppo_analysis': ppo_results,
            'processing_stats': self.processing_stats,
            'timestamp': datetime.now().isoformat()
        }
        
        # DetaylÄ± sonuÃ§lar tablosu oluÅŸtur
        results_df = pd.DataFrame()
        results_df['sample_id'] = range(len(features['basic_features']))
        
        # Fuzzy sonuÃ§larÄ± ekle
        if 'probabilities' in fuzzy_results:
            results_df['fuzzy_probability'] = fuzzy_results['probabilities']
            results_df['fuzzy_prediction'] = fuzzy_results['binary_predictions']
        
        # GerÃ§ek labellarÄ± ekle (varsa)
        if features['labels'] is not None:
            results_df['true_label'] = features['labels']
            results_df['fuzzy_correct'] = (results_df['fuzzy_prediction'] == results_df['true_label']).astype(int)
        
        combined['detailed_results'] = results_df
        
        return combined
    
    def _save_results(self, results: Dict[str, Any], output_dir: str):
        """SonuÃ§larÄ± kaydet"""
        
        # Ana sonuÃ§lar JSON olarak
        with open(os.path.join(output_dir, 'pipeline_results.json'), 'w', encoding='utf-8') as f:
            # JSON serializable hale getir
            json_results = self._make_json_serializable(results)
            json.dump(json_results, f, indent=2, ensure_ascii=False)
        
        # DetaylÄ± sonuÃ§lar CSV olarak
        if 'detailed_results' in results:
            results['detailed_results'].to_csv(
                os.path.join(output_dir, 'detailed_predictions.csv'), 
                index=False
            )
        
        # Fuzzy kurallarÄ± (varsa)
        if 'fuzzy_analysis' in results and 'enhanced_rules' in results['fuzzy_analysis']:
            rules = results['fuzzy_analysis']['enhanced_rules']
            if rules:
                rules_df = pd.DataFrame(rules)
                rules_df.to_csv(
                    os.path.join(output_dir, 'fuzzy_rules.csv'), 
                    index=False
                )
        
        print(f"  âœ“ SonuÃ§lar kaydedildi: {output_dir}")
    
    def _make_json_serializable(self, obj):
        """Objeyi JSON serializable hale getir"""
        if isinstance(obj, dict):
            return {k: self._make_json_serializable(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._make_json_serializable(item) for item in obj]
        elif isinstance(obj, pd.DataFrame):
            return obj.to_dict('records')
        elif isinstance(obj, pd.Series):
            return obj.tolist()
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, (np.int64, np.int32)):
            return int(obj)
        elif isinstance(obj, (np.float64, np.float32)):
            return float(obj)
        elif pd.isna(obj) if not isinstance(obj, (pd.DataFrame, pd.Series)) else False:
            return None
        else:
            return obj
    
    def _create_visualizations(self, results: Dict[str, Any], output_dir: str):
        """GÃ¶rselleÅŸtirmeler oluÅŸtur"""
        try:
            plt.style.use('default')
            
            # 1. Fuzzy Probability DaÄŸÄ±lÄ±mÄ±
            if 'fuzzy_analysis' in results and 'probabilities' in results['fuzzy_analysis']:
                plt.figure(figsize=(12, 8))
                
                # Subplot 1: Probability histogram
                plt.subplot(2, 2, 1)
                probabilities = results['fuzzy_analysis']['probabilities']
                plt.hist(probabilities, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
                plt.title('Fuzzy Logic Probability DaÄŸÄ±lÄ±mÄ±')
                plt.xlabel('Exoplanet Probability')
                plt.ylabel('Frekans')
                plt.grid(True, alpha=0.3)
                
                # Subplot 2: Prediction distribution
                plt.subplot(2, 2, 2)
                predictions = results['fuzzy_analysis']['binary_predictions']
                unique, counts = np.unique(predictions, return_counts=True)
                plt.bar(unique, counts, color=['lightcoral', 'lightgreen'])
                plt.title('Fuzzy Logic Tahmin DaÄŸÄ±lÄ±mÄ±')
                plt.xlabel('Tahmin (0: No Exoplanet, 1: Exoplanet)')
                plt.ylabel('SayÄ±')
                plt.xticks(unique)
                
                # Subplot 3: Confusion Matrix (eÄŸer label varsa)
                if 'detailed_results' in results and 'true_label' in results['detailed_results'].columns:
                    plt.subplot(2, 2, 3)
                    df = results['detailed_results']
                    from sklearn.metrics import confusion_matrix
                    cm = confusion_matrix(df['true_label'], df['fuzzy_prediction'])
                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
                    plt.title('Confusion Matrix')
                    plt.xlabel('Predicted')
                    plt.ylabel('Actual')
                
                # Subplot 4: PPO Results (eÄŸer varsa)
                if 'ppo_analysis' in results and 'best_agents' in results['ppo_analysis']:
                    plt.subplot(2, 2, 4)
                    best_agents = results['ppo_analysis']['best_agents']
                    agent_names = list(best_agents.keys())
                    rewards = [best_agents[name]['reward'] for name in agent_names]
                    
                    plt.bar(range(len(agent_names)), rewards, color='gold')
                    plt.title('En Ä°yi PPO AjanlarÄ± - Final Rewards')
                    plt.xlabel('Fuzzy Output Type')
                    plt.ylabel('Final Reward')
                    plt.xticks(range(len(agent_names)), agent_names, rotation=45)
                
                plt.tight_layout()
                plt.savefig(os.path.join(output_dir, 'pipeline_visualizations.png'), 
                           dpi=300, bbox_inches='tight')
                plt.close()
                
                print("  âœ“ GÃ¶rselleÅŸtirmeler oluÅŸturuldu")
                
        except Exception as e:
            print(f"  âš ï¸ GÃ¶rselleÅŸtirme hatasÄ±: {e}")
    
    def _create_report(self, results: Dict[str, Any], output_dir: str):
        """DetaylÄ± rapor oluÅŸtur"""
        try:
            report_path = os.path.join(output_dir, 'pipeline_report.md')
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("# Exoplanet Detection Pipeline Raporu\n\n")
                f.write(f"**Tarih:** {results['timestamp']}\n\n")
                
                # Veri Ã–zeti
                f.write("## ğŸ“Š Veri Ã–zeti\n\n")
                input_data = results['input_data']
                f.write(f"- **Toplam Ã–rnek:** {input_data['shape'][0]}\n")
                f.write(f"- **Ã–zellik SayÄ±sÄ±:** {input_data['shape'][1]}\n")
                f.write(f"- **SÃ¼tunlar:** {', '.join(input_data['columns'])}\n\n")
                
                # Fuzzy Logic SonuÃ§larÄ±
                f.write("## ğŸ§  Fuzzy Logic Analizi\n\n")
                if 'fuzzy_analysis' in results and 'accuracy' in results['fuzzy_analysis']:
                    fuzzy = results['fuzzy_analysis']
                    if fuzzy['accuracy'] is not None:
                        f.write(f"- **Accuracy:** {fuzzy['accuracy']:.4f}\n")
                    f.write(f"- **Kural SayÄ±sÄ±:** {fuzzy.get('rule_count', 'N/A')}\n")
                    f.write(f"- **Ortalama Probability:** {np.mean(fuzzy['probabilities']):.4f}\n\n")
                
                # PPO SonuÃ§larÄ±
                if 'ppo_analysis' in results and 'total_agents' in results['ppo_analysis']:
                    f.write("## ğŸ¤– PPO AjanlarÄ± Analizi\n\n")
                    ppo = results['ppo_analysis']
                    f.write(f"- **Toplam Ajan:** {ppo['total_agents']}\n")
                    f.write(f"- **Ortalama Reward:** {ppo['avg_reward']:.4f}\n\n")
                    
                    if 'best_agents' in ppo:
                        f.write("### En Ä°yi Ajanlar\n\n")
                        for fuzzy_type, agent_info in ppo['best_agents'].items():
                            f.write(f"- **{fuzzy_type}:** {agent_info['agent_key']} (Reward: {agent_info['reward']:.4f})\n")
                        f.write("\n")
                
                # Ä°ÅŸlem Ä°statistikleri
                f.write("## ğŸ“ˆ Ä°ÅŸlem Ä°statistikleri\n\n")
                stats = results['processing_stats']
                for category, category_stats in stats.items():
                    f.write(f"### {category.title()}\n")
                    for key, value in category_stats.items():
                        f.write(f"- **{key}:** {value}\n")
                    f.write("\n")
                
                f.write("---\n")
                f.write("*Bu rapor Exoplanet Detection Pipeline tarafÄ±ndan otomatik olarak oluÅŸturulmuÅŸtur.*\n")
            
            print(f"  âœ“ DetaylÄ± rapor oluÅŸturuldu: {report_path}")
            
        except Exception as e:
            print(f"  âš ï¸ Rapor oluÅŸturma hatasÄ±: {e}")


def main():
    """Ana fonksiyon - Pipeline'Ä± test et"""
    # Ã–rnek kullanÄ±m
    pipeline = ExoplanetDetectionPipeline()
    
    # K2 dataset ile test
    csv_path = 'feature_extracted__k2_dataset_clean.csv'
    if os.path.exists(csv_path):
        results = pipeline.process_csv(csv_path)
        print(f"\nğŸ‰ Pipeline testi tamamlandÄ±!")
        print(f"ğŸ“ SonuÃ§lar: {results['output_dir']}")
    else:
        print(f"âŒ Test dosyasÄ± bulunamadÄ±: {csv_path}")


if __name__ == "__main__":
    main()